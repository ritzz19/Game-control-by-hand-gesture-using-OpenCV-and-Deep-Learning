{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Swati\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Swati\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\Swati\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import cv2 \n",
    "import numpy as np\n",
    "from keras import applications\n",
    "\n",
    "\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk\n",
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D,AveragePooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras_applications import vgg16\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import os,glob\n",
    "from os import listdir,makedirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "from keras_squeezenet import SqueezeNet\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Activation, Dropout, Convolution2D, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend\n",
    "import os\n",
    "\n",
    "IMG_SAVE_PATH = 'image_data'\n",
    "\n",
    "CLASS_MAP = {\n",
    "    \"fist\": 0,\n",
    "    \"hifi\": 1,\n",
    "    \"none\": 2,\n",
    "    \"thumbsup\": 3,\n",
    "    \"v\": 4\n",
    "}\n",
    "\n",
    "NUM_CLASSES = len(CLASS_MAP)\n",
    "\n",
    "\n",
    "def mapper(val):\n",
    "    return CLASS_MAP[val]\n",
    "\n",
    "# load images from the directory\n",
    "dataset1 = []\n",
    "for directory in os.listdir(IMG_SAVE_PATH):\n",
    "    path = os.path.join(IMG_SAVE_PATH, directory)\n",
    "    if not os.path.isdir(path):\n",
    "        continue\n",
    "    for item in os.listdir(path):\n",
    "        # to make sure no hidden files get in our way\n",
    "        if item.startswith(\".\"):\n",
    "            continue\n",
    "        img = cv2.imread(os.path.join(path, item))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        dataset1.append([img, directory])\n",
    "\n",
    "data, labels = zip(*dataset1)\n",
    "labels = list(map(mapper, labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2773, 224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2773, 224, 224, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing the data\n",
    "input_data = np.array(data)\n",
    "print(input_data.shape)\n",
    "label = np.array(labels)\n",
    "input_data = input_data/255.0\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "import keras\n",
    "import keras.utils\n",
    "from keras import utils as np_utils\n",
    "label = keras.utils.to_categorical(label, num_classes=5,dtype='i1')\n",
    "#label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2773, 224, 224, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2773, 224, 224, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2773, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data, label, test_size = 0.3, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1941, 224, 224, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1941, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import keras\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import os # provides a way of using operating system dependent functionality\n",
    "import cv2 #Image handling library\n",
    "import numpy as np\n",
    "\n",
    "# Import of keras model and hidden layers for our convolutional network\n",
    "from keras.layers import Conv2D, Activation, MaxPool2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(224,224,3), kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.001)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001), bias_regularizer=regularizers.l2(0.001)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001), bias_regularizer=regularizers.l2(0.001)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "opt = Adam\n",
    "model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(832, 224, 224, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(832, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpoint = ModelCheckpoint(\"CV_game.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor = 'val_loss', # value being monitored for improvement\n",
    "                          min_delta = 0, #Abs value and is the min change required before we stop\n",
    "                          patience = 3, #Number of epochs we wait before stopping \n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True) #keeps the best weigths once stopped\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.50225, saving model to CV_game.h5\n",
      "31/31 - 94s - loss: 1.3610 - accuracy: 0.6795 - val_loss: 0.5022 - val_accuracy: 0.9363\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.50225 to 0.37436, saving model to CV_game.h5\n",
      "31/31 - 89s - loss: 0.2267 - accuracy: 0.9737 - val_loss: 0.3744 - val_accuracy: 0.9135\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37436 to 0.22024, saving model to CV_game.h5\n",
      "31/31 - 89s - loss: 0.1721 - accuracy: 0.9856 - val_loss: 0.2202 - val_accuracy: 0.9916\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.22024 to 0.21869, saving model to CV_game.h5\n",
      "31/31 - 89s - loss: 0.1380 - accuracy: 0.9928 - val_loss: 0.2187 - val_accuracy: 0.9832\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.21869 to 0.16990, saving model to CV_game.h5\n",
      "31/31 - 89s - loss: 0.1187 - accuracy: 0.9974 - val_loss: 0.1699 - val_accuracy: 0.9928\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.16990 to 0.13485, saving model to CV_game.h5\n",
      "31/31 - 89s - loss: 0.1088 - accuracy: 1.0000 - val_loss: 0.1348 - val_accuracy: 0.9976\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.13485 to 0.12451, saving model to CV_game.h5\n",
      "31/31 - 89s - loss: 0.1061 - accuracy: 0.9990 - val_loss: 0.1245 - val_accuracy: 0.9976\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.12451 to 0.12051, saving model to CV_game.h5\n",
      "31/31 - 89s - loss: 0.0986 - accuracy: 0.9995 - val_loss: 0.1205 - val_accuracy: 0.9988\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.12051 to 0.11185, saving model to CV_game.h5\n",
      "31/31 - 89s - loss: 0.0939 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9988\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.11185\n",
      "31/31 - 91s - loss: 0.0903 - accuracy: 0.9995 - val_loss: 0.1180 - val_accuracy: 0.9976\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "          batch_size = 64,\n",
    "          epochs = 10,\n",
    "          verbose = 2,\n",
    "          callbacks = callbacks,\n",
    "          validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "model.save('CV_game.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 8s 317ms/step - loss: 0.1180 - accuracy: 0.9976\n",
      "Test accuracy: 99.76%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tLoss, tAccuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Test accuracy: {:2.2f}%'.format(tAccuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, array([0, 0, 1, 0, 0], dtype=int8))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction[0]), y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Swati\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Swati\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\Swati\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALIBRATION COMPLETE!!!!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from imutils import resize\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class GestureDetector:\n",
    "    def __init__(self, para=None):\n",
    "        self.check_paras = para\n",
    "        self.bg, self.area, self.frame_copy = None, None, None\n",
    "        self.key = None\n",
    "        self.showing = True\n",
    "        self.num_frames = 0\n",
    "        self.camera = cv2.VideoCapture(0)\n",
    "        self.out = None\n",
    "\n",
    "    def end_feed(self):\n",
    "        cv2.destroyAllWindows()\n",
    "        self.camera.release()\n",
    "\n",
    "    def loop_feed(self):\n",
    "        while self.showing:\n",
    "            self.show_video_feed()\n",
    "\n",
    "    def avg_backGr_get(self, image, weight):\n",
    "        if self.bg is None:\n",
    "            self.bg = image.copy().astype(\"float\")\n",
    "            return\n",
    "        cv2.accumulateWeighted(image, self.bg, weight)\n",
    "\n",
    "    def isolate_hand(self, image, threshold=25):\n",
    "        difference = cv2.absdiff(self.bg.astype(\"uint8\"), image)\n",
    "        threshold_area = cv2.threshold(difference, threshold, 255, cv2.THRESH_BINARY)[1]\n",
    "        (contours, _) = cv2.findContours(threshold_area.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if len(contours) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            isolated_hand = max(contours, key=cv2.contourArea)\n",
    "            return threshold_area, isolated_hand\n",
    "\n",
    "    def show_video_feed(self, calibration_no=10, show_windows=True):\n",
    "        weight = 0.5\n",
    "        # Keep Width 240, Height 225\n",
    "        # Camera POV, Left Edge: 450, 690 ; Right Edge:\n",
    "        sc_right, sc_left, sc_top, sc_bottom = 450, 690, 70, 295\n",
    "        grabbed, frame = self.camera.read()\n",
    "        frame = resize(frame, width=700)\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        self.frame_copy = frame.copy()\n",
    "\n",
    "        # TODO Try modifying\n",
    "        region = frame[sc_top:sc_bottom, sc_right:sc_left]\n",
    "        region = cv2.cvtColor(region, cv2.COLOR_BGR2GRAY)\n",
    "        region = cv2.GaussianBlur(region, (7, 7), 0)\n",
    "\n",
    "        if self.num_frames < calibration_no:\n",
    "            self.avg_backGr_get(region, weight)\n",
    "            temp = cv2.imread(\"none.png\")\n",
    "            cv2.imwrite(\"livefeed.png\", temp)\n",
    "            del temp\n",
    "        elif self.num_frames == calibration_no:\n",
    "            print(\"CALIBRATION COMPLETE!!!!\")\n",
    "        else:\n",
    "            hand = self.isolate_hand(region)\n",
    "            if hand is not None:\n",
    "                self.area, hand_cont = hand\n",
    "                cv2.drawContours(self.frame_copy, [hand_cont + (sc_right, sc_top)], -1, (0, 0, 255))\n",
    "                if show_windows:\n",
    "                    cv2.imshow('Isolated hand', self.area)\n",
    "            else:\n",
    "                 temp = cv2.imread(\"none.png\")\n",
    "                 cv2.imshow('Isolated hand', temp)\n",
    "\n",
    "        cv2.rectangle(self.frame_copy, (sc_left, sc_top), (sc_right, sc_bottom), (0, 255, 0), 2)\n",
    "        self.num_frames += 1\n",
    "        if show_windows:\n",
    "            cv2.imshow(\"Overall image\", self.frame_copy)\n",
    "        self.save_isolated_frame()\n",
    "\n",
    "        keypress = cv2.waitKey(1) & 0xFF\n",
    "        if keypress == ord(\"q\"):\n",
    "            self.showing = False\n",
    "            self.end_feed()\n",
    "            return\n",
    "        elif keypress == ord(\"r\"):\n",
    "            print(\"RECALIBRATE\")\n",
    "            self.camera.release()\n",
    "            self.bg, self.area = None, None\n",
    "            self.num_frames = 0\n",
    "            self.camera = cv2.VideoCapture(0)\n",
    "            self.show_video_feed()\n",
    "            return\n",
    "        else:\n",
    "            self.key = keypress\n",
    "            self.showing = True\n",
    "\n",
    "    def save_isolated_frame(self):\n",
    "        if self.area is not None:\n",
    "            self.out = self.area\n",
    "            cv2.imwrite(\"livefeed.png\", self.area)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    G = GestureDetector()\n",
    "    G.loop_feed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALIBRATION COMPLETE!!!!\n"
     ]
    }
   ],
   "source": [
    "import visualizer\n",
    "import numpy as np\n",
    "from cv2 import imread\n",
    "from time import sleep\n",
    "from joblib import load\n",
    "from pydirectinput import keyUp, keyDown\n",
    "from collections import Counter\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pyautogui\n",
    "from threading import Thread\n",
    "from time import sleep\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "def get_mode(of_this_list):\n",
    "    prediction = Counter(of_this_list)\n",
    "    return prediction.most_common(n=1)[0][0]\n",
    "\n",
    "REV_CLASS_MAP = {\n",
    "    0: \"fist\",\n",
    "    1: \"hifi\",\n",
    "    2: \"none\",\n",
    "    3: \"thumbsup\",\n",
    "    4: \"v\"\n",
    "}\n",
    "\n",
    "\n",
    "def worker(response): #no hand\n",
    "    result1=\"test\"\n",
    "    if response == 2:\n",
    "        pass\n",
    "    elif response == 0: #fist\n",
    "        keyDown('down')\n",
    "    elif response == 1: #hifi\n",
    "        pass\n",
    "    elif response == 3: #thumbsup\n",
    "        keyDown('up')\n",
    "    elif response == 4: #V\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "class Models:\n",
    "    def __init__(self, model_file):\n",
    "        self.model = load_model(model_file)\n",
    "\n",
    "    \n",
    "\n",
    "    def check_frame(self):\n",
    "        check_img = np.asarray(imread(\"livefeed.png\"))\n",
    "        if check_img is not None:\n",
    "            #check_img = img_to_array(check_img)\n",
    "            check_img.resize(224,224,3)\n",
    "            check_img = np.expand_dims(check_img, axis=0)\n",
    "            result = self.model.predict(check_img)[0]\n",
    "            temp = max(result)\n",
    "            for i, this in enumerate(result):\n",
    "                if temp == this:\n",
    "                    return i\n",
    "        \n",
    "     \n",
    "   \n",
    "if __name__ == '__main__':\n",
    "    G = GestureDetector()\n",
    "    started, start_key = False, None\n",
    "    #model_files = ['CV_game.h5']\n",
    "    model_files = ['CV_game.h5']\n",
    "    t_exec = ThreadPoolExecutor()\n",
    "    init_threads = t_exec.map(Models,model_files)\n",
    "    models = [result for result in init_threads]\n",
    "    while G.showing:\n",
    "        G.show_video_feed(50, True)\n",
    "        started = True\n",
    "        if G.out is not None:\n",
    "            process_thread = t_exec.submit(models[0].check_frame)\n",
    "            predict_VGG = process_thread.result()\n",
    "            response = get_mode([predict_VGG])\n",
    "            #print(response)\n",
    "            #print(type(response))\n",
    "            #worker(response)\n",
    "            thread = Thread(target = worker, args = (response, ))\n",
    "            #thread.start()\n",
    "            #thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
